import streamlit as st
import joblib
import re, string
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù€ vectorizer
import gzip
with gzip.open("spam_classifier_model.pkl.gz", "rb") as f:
    model = joblib.load(f)
vectorizer = joblib.load("tfidf_vectorizer.pkl")

# Ø¯ÙˆØ§Ù„ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
def clean_message(message):
    message = str(message).lower()
    message = re.sub(f"[{re.escape(string.punctuation)}]", "", message)
    message = re.sub(r"\d+", "", message)
    message = re.sub(r"\s+", " ", message).strip()
    return message

def preprocess_message(message):
    lemmatizer = WordNetLemmatizer()
    stop_words = set(stopwords.words('english'))

    message = clean_message(message)
    tokens = message.split()
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]

    return " ".join(tokens)

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.title("ğŸ“§ Email Spam Classifier")
st.write("Ø§ÙƒØªØ¨ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ ÙˆÙ‡Ù‚ÙˆÙ„Ùƒ Ø¥Ø°Ø§ ÙƒØ§Ù† Spam ÙˆÙ„Ø§ Ham ğŸ˜‰")

user_input = st.text_area("âœ‰ï¸ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„:")

if st.button("ğŸ” ØªØµÙ†ÙŠÙ"):
    if user_input.strip() == "":
        st.warning("Ù…Ù† ÙØ¶Ù„Ùƒ Ø§ÙƒØªØ¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„.")
    else:
        cleaned_input = preprocess_message(user_input)
        vectorized_input = vectorizer.transform([cleaned_input])
        prediction = model.predict(vectorized_input)[0]
        st.success(f"ğŸ” ØªÙ… ØªØµÙ†ÙŠÙÙ‡ ÙƒÙ€: **{prediction.upper()}**")
